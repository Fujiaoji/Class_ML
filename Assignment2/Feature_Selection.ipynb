{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dffe6cf7",
   "metadata": {},
   "source": [
    "# Assignment 2 - Sound Recognition-Feature Selection, Taking domain-specific no window as example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abf52ca",
   "metadata": {},
   "source": [
    "## 1. Pre-processing: Load All Recordings, Median Filter, and FFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04c8aa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import scipy\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io.wavfile as wavfile\n",
    "\n",
    "from scipy.fftpack import fft\n",
    "from scipy import signal\n",
    "\n",
    "\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f66a393",
   "metadata": {},
   "source": [
    "# 2. Domain Specific Models To Select Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11e25bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(classes):\n",
    "    class Audios():\n",
    "        f= None\n",
    "        fs= None\n",
    "        tag= None\n",
    "    tags=[]\n",
    "    data=[]\n",
    "\n",
    "    for i_class in classes:\n",
    "        for each_file in glob.glob(\"Dataset/\"+i_class+\"/*.wav\"):\n",
    "            audio=Audios()\n",
    "            f, fs=librosa.load(each_file, sr=None, mono=True, offset=0.0, duration=None) # load file\n",
    "            f = signal.medfilt(f, kernel_size=3) # median filter with zero padding \n",
    "            audio.f= f\n",
    "            audio.fs= fs\n",
    "            audio.tag=i_class\n",
    "            tags.append(audio.tag)\n",
    "            data.append(audio)\n",
    "    return data, tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "417a6a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"Alarm\", \"Silence\", \"Music\", \"Microwave\", \"Clean\", \"Blender\"]\n",
    "data, tags = load_data(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055f3e4b",
   "metadata": {},
   "source": [
    "## 2. Model Building: Domain Model with Windows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8ede4f",
   "metadata": {},
   "source": [
    "## I. Training and Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b37e118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutting_into_windows(sample, sample_fs):\n",
    "    \"\"\"Cutting sample into windows, every is 6s\"\"\"\n",
    "    window_size = int(sample_fs * 2)# 6s instances/window\n",
    "    window_overlap = window_size // 2\n",
    "    windows = []\n",
    "    i = 0\n",
    "    win_count = 0\n",
    "    while ((i + window_size) < len(sample)) and (win_count < 20):\n",
    "        windows.append(sample[i: i + window_size])\n",
    "        i = i + window_size - window_overlap\n",
    "        win_count = win_count + 1\n",
    "    return np.array(windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af12a21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfcc_window_features(FFT_SIZE, num_freq_bins, num_time_bins, data):\n",
    "    \"\"\"Obtain all data's features\"\"\"\n",
    "    # Use mfcc\n",
    "    features=[]\n",
    "    for sample in data:\n",
    "        windows = cutting_into_windows(sample.f, sample.fs)\n",
    "        sample_features = []\n",
    "            \n",
    "        for window in windows:\n",
    "            # If only use mfcc\n",
    "            mfccs=librosa.feature.mfcc(y=window,sr=sample.fs,n_mfcc=20)\n",
    "            mfccs=np.mean(mfccs.T, axis=0)\n",
    "            sample_features.append(mfccs.reshape((-1, )))\n",
    "\n",
    "            pass\n",
    "        features.append(np.array(sample_features).mean(axis=0))\n",
    "    features = np.array(features)\n",
    "    return features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28aca59d-d93a-4bce-a097-4f6a4ff0c6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_window_features(FFT_SIZE, num_freq_bins, num_time_bins, data):\n",
    "    \"\"\"Obtain all data's features\"\"\"\n",
    "    \n",
    "    features=[]\n",
    "    for sample in data:\n",
    "        windows = cutting_into_windows(sample.f, sample.fs)\n",
    "        sample_features = []\n",
    "            \n",
    "        for window in windows:\n",
    "            # If use other, can self select\n",
    "\n",
    "            f,t,pxx = signal.spectrogram(window, nperseg=FFT_SIZE, fs=sample.fs, noverlap=int(FFT_SIZE/4))\n",
    "            # max_index = np.argmax(pxx, axis=0)\n",
    "            # min_index = np.argmin(pxx, axis=0)\n",
    "            # var = np.var(pxx,axis=0)\n",
    "            max_per_window = np.max(pxx, axis=0)\n",
    "            min_per_window = np.min(pxx, axis=0)\n",
    "            # sum_per_window = np.sum(pxx, axis=0)\n",
    "            # mean_per_window = np.mean(pxx, axis=0)\n",
    "            # std_per_window = np.std(pxx, axis=0)\n",
    "            median_per_window = np.median(pxx, axis=0)\n",
    "            quan_per_window_1 = np.quantile(pxx, 0.25, axis=0)\n",
    "            quan_per_window_3 = np.quantile(pxx, 0.75, axis=0)\n",
    "\n",
    "            sample_features.append([max_per_window.mean(), min_per_window.mean(), median_per_window.mean(), quan_per_window_1.mean(), quan_per_window_3.mean()])\n",
    "                #  max_index.mean(), min_index.mean()])#, var.mean(), max_per_window.mean(), min_per_window.mean(), sum_per_window.mean(),\\\n",
    "                 #mean_per_window.mean(), std_per_window.mean(), median_per_window.mean(), quan_per_window_1.mean(), quan_per_window_3.mean()])\n",
    "            pass\n",
    "        features.append(np.array(sample_features).mean(axis=0))\n",
    "    features = np.array(features)\n",
    "    return features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "607b3046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Cross Validation Score from Training:\n",
      "0.9888888888888889\n",
      "\n",
      "\n",
      "Testing Accuracy: 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Model/feature_selection_model.joblib']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FFT_SIZE=1024\n",
    "num_freq_bins=20\n",
    "num_time_bins=20\n",
    "\n",
    "\n",
    "# domain_window_features = get_mfcc_window_features(FFT_SIZE, num_freq_bins, num_time_bins, data)\n",
    "domain_window_features = get_window_features(FFT_SIZE, num_freq_bins, num_time_bins, data)\n",
    "\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "domain_window_features = scaler.fit_transform(domain_window_features)\n",
    "\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(domain_window_features, tags, test_size=0.2, random_state=100)\n",
    "clf = RandomForestClassifier(random_state=100)\n",
    "# clf = SVC()\n",
    "clf.fit(xtrain, ytrain)\n",
    "ypred = clf.predict(xtrain)\n",
    "\n",
    "scores = cross_val_score(clf, xtrain, ytrain, cv=10)\n",
    "print('Average Cross Validation Score from Training:', scores.mean(), sep='\\n', end='\\n\\n\\n')\n",
    "\n",
    "#testing the model\n",
    "ypred = clf.predict(xtest)\n",
    "\n",
    "cm = confusion_matrix(ytest, ypred)\n",
    "cr = classification_report(ytest, ypred)\n",
    "\n",
    "# print('Confusion Matrix:', cm, sep='\\n', end='\\n\\n\\n')\n",
    "# print('Test Statistics:', cr, sep='\\n', end='\\n\\n\\n')\n",
    "\n",
    "print('Testing Accuracy:', accuracy_score(ytest, ypred))\n",
    "# names = [\"Alarm\", \"Blender\", \"Clean\", \"Microwave\", \"Music\", \"Silence\"]\n",
    "# cm_display = ConfusionMatrixDisplay(cm, display_labels=names)\n",
    "# cm_display.plot()\n",
    "# plt.savefig(\"Pictures/feature_selection.png\")\n",
    "# plt.show()\n",
    "\n",
    "joblib.dump(clf, \"Model/feature_selection_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defcd603",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8100d24-ccdf-4e83-9274-b851a3f6a0a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e398ee05330ab2b67a6fd13ddd7dfd461ae6aacfb911fe13bbd65834d6e300e2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
